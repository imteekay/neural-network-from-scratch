{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:35:55.202032Z","iopub.execute_input":"2025-01-19T16:35:55.202437Z","iopub.status.idle":"2025-01-19T16:36:01.623897Z","shell.execute_reply.started":"2025-01-19T16:35:55.202401Z","shell.execute_reply":"2025-01-19T16:36:01.622580Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:36:01.626647Z","iopub.execute_input":"2025-01-19T16:36:01.627200Z","iopub.status.idle":"2025-01-19T16:36:01.668349Z","shell.execute_reply.started":"2025-01-19T16:36:01.627148Z","shell.execute_reply":"2025-01-19T16:36:01.667064Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n41995         0         0         0         0         0  \n41996         0         0         0         0         0  \n41997         0         0         0         0         0  \n41998         0         0         0         0         0  \n41999         0         0         0         0         0  \n\n[42000 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41997</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41998</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41999</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>42000 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"data = np.array(data)\nm, n = data.shape\nm, n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:36:01.670198Z","iopub.execute_input":"2025-01-19T16:36:01.670617Z","iopub.status.idle":"2025-01-19T16:36:01.899221Z","shell.execute_reply.started":"2025-01-19T16:36:01.670546Z","shell.execute_reply":"2025-01-19T16:36:01.897937Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(42000, 785)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"number_of_tests = int(m * 0.15)\n\nnp.random.shuffle(data)\n\ntest_data = data[0:number_of_tests].T\nY_test = test_data[0]\nX_test = test_data[1:n]\nX_test = X_test / 255.0\n\ntrain_data = data[number_of_tests:m].T\nY_train = train_data[0]\nX_train = train_data[1:n]\nX_train = X_train / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:36:01.902177Z","iopub.execute_input":"2025-01-19T16:36:01.902679Z","iopub.status.idle":"2025-01-19T16:36:02.625952Z","shell.execute_reply.started":"2025-01-19T16:36:01.902619Z","shell.execute_reply":"2025-01-19T16:36:02.624594Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class NeuralNetwork:\n    def __init__(self, X_train, Y_train, X_test, Y_test, LR, iterations, layer_dimensions, mini_batch_size):\n        self.X_train = X_train\n        self.Y_train = Y_train\n        self.Y_one_hot = self.one_hot(Y_train)\n        self.X_test = X_test\n        self.Y_test = Y_test\n        self.LR = LR\n        self.iterations = iterations\n        self.layer_dimensions = layer_dimensions\n        self.mini_batch_size = mini_batch_size\n        self.num_of_batches = len(X_train[0]) // mini_batch_size\n\n        W, B = self.init_params(layer_dimensions)\n        self.W = W\n        self.B = B\n\n        self.Z = [None for i in range(len(layer_dimensions))]\n        self.Z_test = [None for i in range(len(layer_dimensions))]\n        self.dZ = [None for i in range(len(layer_dimensions))]\n        self.dW = [None for i in range(len(layer_dimensions))]\n        self.dB = [None for i in range(len(layer_dimensions))]\n\n    def init_params(self, layer_dimensions):\n        W = [None]\n        B = [None]\n    \n        for l in range(1, len(layer_dimensions)):\n            current_layer_dimension = layer_dimensions[l]\n            previous_layer_dimension = layer_dimensions[l - 1]\n            w = np.random.randn(current_layer_dimension, previous_layer_dimension) * np.sqrt(2 / previous_layer_dimension)\n            b = np.random.randn(current_layer_dimension, 1)\n            W.append(w)\n            B.append(b)\n\n        return W, B\n\n    def one_hot(self, Y):\n        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n        one_hot_Y[np.arange(Y.size), Y] = 1\n        return one_hot_Y.T\n    \n    def ReLU(self, Z):\n        return np.maximum(Z, 0)\n\n    def derivative_of_ReLU(self, Z):\n        return Z > 0\n    \n    def LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, Z, alpha * Z)\n    \n    def derivative_of_LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, 1, alpha)\n    \n    def softmax(self, Z):\n        expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n        return expZ / np.sum(expZ, axis=0, keepdims=True)\n        \n    def _is_last_layer(self, layer):\n        return layer == len(self.layer_dimensions) - 1\n\n    def forward_propagation(self):\n        for layer in range(1, len(self.layer_dimensions)):\n            self.Z[layer] = self.W[layer].dot(self.A[layer - 1]) + self.B[layer]\n\n            if self._is_last_layer(layer):\n                self.A[layer] = self.softmax(self.Z[layer])\n            else:\n                self.A[layer] = self.LeakyReLU(self.Z[layer])\n\n    def backward_propagation(self, lambda_reg=0.01):\n        for layer in range(len(self.layer_dimensions) - 1, 0, -1):\n            if self._is_last_layer(layer):\n                self.dZ[layer] = self.A[layer] - self.Y_one_hot_batch\n            else:\n                self.dZ[layer] = self.W[layer + 1].T.dot(self.dZ[layer + 1]) * self.derivative_of_LeakyReLU(self.Z[layer])\n\n            self.dW[layer] = 1 / self.mini_batch_size * self.dZ[layer].dot(self.A[layer - 1].T) + (lambda_reg / self.mini_batch_size) * self.W[layer]\n            self.dB[layer] = 1 / self.mini_batch_size * np.sum(self.dZ[layer]) \n    \n    def update_params(self):\n        for layer in range(1, len(self.layer_dimensions)):\n            self.W[layer] = self.W[layer] - self.LR * self.dW[layer]\n            self.B[layer] = self.B[layer] - self.LR * self.dB[layer]\n    \n    def get_predictions(self, A):\n        return np.argmax(A, 0)\n    \n    def get_accuracy(self, predictions, Y):\n        return np.sum(predictions == Y) / Y.size\n    \n    def predict(self):\n        for layer in range(1, len(self.layer_dimensions)):\n            self.Z_test[layer] = self.W[layer].dot(self.A_test[layer - 1]) + self.B[layer]\n\n            if self._is_last_layer(layer):\n                self.A_test[layer] = self.softmax(self.Z_test[layer])\n            else:\n                self.A_test[layer] = self.LeakyReLU(self.Z_test[layer])\n\n        return self.get_predictions(self.A_test[-1])\n    \n    def gradient_descent(self):\n        train = []\n        test = []\n        \n        for i in range(self.iterations + 1):\n            if i % 10 == 0:\n                print(\"==== Iteration:\", i, \"====\")\n\n            for current_batch in range(0, self.num_of_batches):\n                self.current_batch = current_batch\n                self.batch_starting_point = current_batch * self.mini_batch_size\n                self.X_train_batch = self.X_train[:, self.batch_starting_point:self.batch_starting_point + self.mini_batch_size]\n                self.Y_train_batch = self.Y_train[self.batch_starting_point:self.batch_starting_point + self.mini_batch_size]\n                self.A = [self.X_train_batch] + [None for i in range(len(layer_dimensions) - 1)]\n                self.A_test = [self.X_test] + [None for i in range(len(layer_dimensions) - 1)]\n                self.Y_one_hot_batch = self.Y_one_hot[:, self.batch_starting_point:self.batch_starting_point + self.mini_batch_size]\n                \n                self.forward_propagation()\n                self.backward_propagation()\n                self.update_params()\n                \n                training_predictions = self.get_predictions(self.A[-1])\n                training_accuracy = self.get_accuracy(training_predictions, self.Y_train_batch)\n                test_predictions = self.predict()\n                test_accuracy = self.get_accuracy(test_predictions, self.Y_test)\n        \n                train.append(training_accuracy)\n                test.append(test_accuracy)\n        \n                if i % 10 == 0:\n                    print(\"==== Batch:\", current_batch + 1, '====')\n                    print('- training_accuracy: ', training_accuracy)\n                    print('- test_accuracy: ', test_accuracy)\n    \n        return train, test\n\nLR = 0.1\nITERATIONS = 3000\nlayer_dimensions = [784, 200, 200, 200, 10]\nmini_batch_size = 2100 # 17 mini batches of 2100 training examples (35700 examples in total)\nnumber_of_batches = len(X_train[0]) // mini_batch_size\n\nnn = NeuralNetwork(X_train, Y_train, X_test, Y_test, LR, ITERATIONS, layer_dimensions, mini_batch_size)\ntrain, test = nn.gradient_descent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:36:02.627920Z","iopub.execute_input":"2025-01-19T16:36:02.628280Z","iopub.status.idle":"2025-01-19T16:37:16.047848Z","shell.execute_reply.started":"2025-01-19T16:36:02.628246Z","shell.execute_reply":"2025-01-19T16:37:16.045914Z"}},"outputs":[{"name":"stdout","text":"==== Iteration: 0 ====\n==== Batch: 1 ====\n- training_accuracy:  0.09571428571428571\n- test_accuracy:  0.10158730158730159\n==== Batch: 2 ====\n- training_accuracy:  0.10285714285714286\n- test_accuracy:  0.15317460317460319\n==== Batch: 3 ====\n- training_accuracy:  0.1376190476190476\n- test_accuracy:  0.17682539682539683\n==== Batch: 4 ====\n- training_accuracy:  0.18619047619047618\n- test_accuracy:  0.24174603174603174\n==== Batch: 5 ====\n- training_accuracy:  0.23761904761904762\n- test_accuracy:  0.2722222222222222\n==== Batch: 6 ====\n- training_accuracy:  0.28095238095238095\n- test_accuracy:  0.37873015873015875\n==== Batch: 7 ====\n- training_accuracy:  0.3880952380952381\n- test_accuracy:  0.4695238095238095\n==== Batch: 8 ====\n- training_accuracy:  0.4742857142857143\n- test_accuracy:  0.43793650793650796\n==== Batch: 9 ====\n- training_accuracy:  0.4328571428571429\n- test_accuracy:  0.4922222222222222\n==== Batch: 10 ====\n- training_accuracy:  0.48095238095238096\n- test_accuracy:  0.38333333333333336\n==== Batch: 11 ====\n- training_accuracy:  0.38666666666666666\n- test_accuracy:  0.36238095238095236\n==== Batch: 12 ====\n- training_accuracy:  0.3438095238095238\n- test_accuracy:  0.4687301587301587\n==== Batch: 13 ====\n- training_accuracy:  0.48\n- test_accuracy:  0.5761904761904761\n==== Batch: 14 ====\n- training_accuracy:  0.5752380952380952\n- test_accuracy:  0.5465079365079365\n==== Batch: 15 ====\n- training_accuracy:  0.5476190476190477\n- test_accuracy:  0.5285714285714286\n==== Batch: 16 ====\n- training_accuracy:  0.5514285714285714\n- test_accuracy:  0.4876190476190476\n==== Batch: 17 ====\n- training_accuracy:  0.5057142857142857\n- test_accuracy:  0.5273015873015873\n==== Iteration: 10 ====\n==== Batch: 1 ====\n- training_accuracy:  0.9133333333333333\n- test_accuracy:  0.9031746031746032\n==== Batch: 2 ====\n- training_accuracy:  0.9047619047619048\n- test_accuracy:  0.9042857142857142\n==== Batch: 3 ====\n- training_accuracy:  0.9152380952380952\n- test_accuracy:  0.9044444444444445\n==== Batch: 4 ====\n- training_accuracy:  0.9123809523809524\n- test_accuracy:  0.9057142857142857\n==== Batch: 5 ====\n- training_accuracy:  0.920952380952381\n- test_accuracy:  0.9068253968253969\n==== Batch: 6 ====\n- training_accuracy:  0.9195238095238095\n- test_accuracy:  0.9044444444444445\n==== Batch: 7 ====\n- training_accuracy:  0.9219047619047619\n- test_accuracy:  0.9036507936507937\n==== Batch: 8 ====\n- training_accuracy:  0.9142857142857143\n- test_accuracy:  0.9049206349206349\n==== Batch: 9 ====\n- training_accuracy:  0.9176190476190477\n- test_accuracy:  0.9033333333333333\n==== Batch: 10 ====\n- training_accuracy:  0.9147619047619048\n- test_accuracy:  0.9053968253968254\n==== Batch: 11 ====\n- training_accuracy:  0.909047619047619\n- test_accuracy:  0.8988888888888888\n==== Batch: 12 ====\n- training_accuracy:  0.8952380952380953\n- test_accuracy:  0.8966666666666666\n==== Batch: 13 ====\n- training_accuracy:  0.9052380952380953\n- test_accuracy:  0.8957142857142857\n==== Batch: 14 ====\n- training_accuracy:  0.9147619047619048\n- test_accuracy:  0.9052380952380953\n==== Batch: 15 ====\n- training_accuracy:  0.9085714285714286\n- test_accuracy:  0.9017460317460317\n==== Batch: 16 ====\n- training_accuracy:  0.9261904761904762\n- test_accuracy:  0.9085714285714286\n==== Batch: 17 ====\n- training_accuracy:  0.9185714285714286\n- test_accuracy:  0.9049206349206349\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 146\u001b[0m\n\u001b[1;32m    143\u001b[0m number_of_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m mini_batch_size\n\u001b[1;32m    145\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(X_train, Y_train, X_test, Y_test, LR, ITERATIONS, layer_dimensions, mini_batch_size)\n\u001b[0;32m--> 146\u001b[0m train, test \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[5], line 121\u001b[0m, in \u001b[0;36mNeuralNetwork.gradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_one_hot_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_one_hot[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_starting_point:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_starting_point \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_propagation()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m    124\u001b[0m training_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_predictions(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n","Cell \u001b[0;32mIn[5], line 76\u001b[0m, in \u001b[0;36mNeuralNetwork.backward_propagation\u001b[0;34m(self, lambda_reg)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[layer] \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY_one_hot_batch\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdZ\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_of_LeakyReLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ[layer])\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ[layer]\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA[layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m (lambda_reg \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW[layer]\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdB[layer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ[layer])\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import plotly.graph_objs as go\nimport plotly.io as pio\n\niterations = [i for i in range((ITERATIONS + 1) * number_of_batches)]\n\ntrain_data = pd.DataFrame({\n    'x': iterations,\n    'y': train\n})\n\ntest_data = pd.DataFrame({\n    'x': iterations,\n    'y': test\n})\n\ntrace1 = go.Scatter(x = train_data.x,\n                    y = train_data.y,\n                    mode = \"lines\",\n                    name = \"training\",\n                    marker = dict(color = 'rgba(16, 112, 2, 0.8)'))\n\ntrace2 = go.Scatter(x = test_data.x,\n                    y = test_data.y,\n                    mode = \"lines+markers\",\n                    name = \"test\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'))\n\ndata = [trace1, trace2]\nfig = dict(data = data)\npio.show(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:37:16.048730Z","iopub.status.idle":"2025-01-19T16:37:16.049144Z","shell.execute_reply.started":"2025-01-19T16:37:16.048955Z","shell.execute_reply":"2025-01-19T16:37:16.048976Z"}},"outputs":[],"execution_count":null}]}