{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\ndata = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-21T11:44:45.253412Z","iopub.execute_input":"2024-11-21T11:44:45.253815Z","iopub.status.idle":"2024-11-21T11:44:50.292129Z","shell.execute_reply.started":"2024-11-21T11:44:45.253777Z","shell.execute_reply":"2024-11-21T11:44:50.290881Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T11:44:50.294223Z","iopub.execute_input":"2024-11-21T11:44:50.294594Z","iopub.status.idle":"2024-11-21T11:44:50.341497Z","shell.execute_reply.started":"2024-11-21T11:44:50.294548Z","shell.execute_reply":"2024-11-21T11:44:50.340418Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0          1       0       0       0       0       0       0       0       0   \n1          0       0       0       0       0       0       0       0       0   \n2          1       0       0       0       0       0       0       0       0   \n3          4       0       0       0       0       0       0       0       0   \n4          0       0       0       0       0       0       0       0       0   \n...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n41995      0       0       0       0       0       0       0       0       0   \n41996      1       0       0       0       0       0       0       0       0   \n41997      7       0       0       0       0       0       0       0       0   \n41998      6       0       0       0       0       0       0       0       0   \n41999      9       0       0       0       0       0       0       0       0   \n\n       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n2           0  ...         0         0         0         0         0   \n3           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n...       ...  ...       ...       ...       ...       ...       ...   \n41995       0  ...         0         0         0         0         0   \n41996       0  ...         0         0         0         0         0   \n41997       0  ...         0         0         0         0         0   \n41998       0  ...         0         0         0         0         0   \n41999       0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n2             0         0         0         0         0  \n3             0         0         0         0         0  \n4             0         0         0         0         0  \n...         ...       ...       ...       ...       ...  \n41995         0         0         0         0         0  \n41996         0         0         0         0         0  \n41997         0         0         0         0         0  \n41998         0         0         0         0         0  \n41999         0         0         0         0         0  \n\n[42000 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41997</th>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41998</th>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41999</th>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>42000 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data = np.array(data)\nm, n = data.shape\nm, n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T11:44:50.342622Z","iopub.execute_input":"2024-11-21T11:44:50.342966Z","iopub.status.idle":"2024-11-21T11:44:50.484953Z","shell.execute_reply.started":"2024-11-21T11:44:50.342934Z","shell.execute_reply":"2024-11-21T11:44:50.483909Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(42000, 785)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"number_of_tests = int(m * 0.3)\n\nnp.random.shuffle(data)\n\ntest_data = data[0:number_of_tests].T\nY_test = test_data[0]\nX_test = test_data[1:n]\nX_test = X_test / 255.0\n\ntrain_data = data[number_of_tests:m].T\nY_train = train_data[0]\nX_train = train_data[1:n]\nX_train = X_train / 255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T11:44:50.487363Z","iopub.execute_input":"2024-11-21T11:44:50.487793Z","iopub.status.idle":"2024-11-21T11:44:51.175550Z","shell.execute_reply.started":"2024-11-21T11:44:50.487746Z","shell.execute_reply":"2024-11-21T11:44:51.174572Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# def init_params():\n#     W1 = np.random.rand(100, 784) * 0.01\n#     B1 = np.zeros((100, 1))\n#     W2 = np.random.rand(10, 100) * 0.01\n#     B2 = np.zeros((10, 1))\n#     return W1, B1, W2, B2\n\n# def ReLU(Z):\n#     return np.maximum(Z, 0)\n\n# def softmax(Z):\n#     return np.exp(Z) / sum(np.exp(Z))\n    \n# def forward_propagation(W1, B1, W2, B2, X):\n#     Z1 = W1.dot(X) + B1\n#     A1 = ReLU(Z1)\n#     Z2 = W2.dot(A1) + B2\n#     A2 = softmax(Z2)\n#     return Z1, A1, Z2, A2\n\n# def derivative_of_ReLU(Z):\n#     return Z > 0\n\n# def one_hot(Y):\n#     one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n#     one_hot_Y[np.arange(Y.size), Y] = 1\n#     return one_hot_Y.T\n\n# def backward_propagation(Z1, A1, Z2, A2, W1, W2, X, Y):\n#     dZ2 = A2 - Y\n#     dW2 = 1 / m * dZ2.dot(A1.T)\n#     dB2 = 1 / m * np.sum(dZ2)\n#     dZ1 = W2.T.dot(dZ2) * derivative_of_ReLU(Z1)\n#     dW1 = 1 / m * dZ1.dot(X.T)\n#     dB1 = 1 / m * np.sum(dZ1)\n#     return dW1, dB1, dW2, dB2\n\n# def update_params(W1, B1, W2, B2, dW1, dB1, dW2, dB2, LR):\n#     W1 = W1 - LR * dW1\n#     B1 = B1 - LR * dB1    \n#     W2 = W2 - LR * dW2  \n#     B2 = B2 - LR * dB2    \n#     return W1, B1, W2, B2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.186927Z","iopub.execute_input":"2024-11-20T20:01:16.187291Z","iopub.status.idle":"2024-11-20T20:01:16.193046Z","shell.execute_reply.started":"2024-11-20T20:01:16.187256Z","shell.execute_reply":"2024-11-20T20:01:16.191855Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# def get_predictions(A2):\n#     return np.argmax(A2, 0)\n\n# def get_accuracy(predictions, Y):\n#     return np.sum(predictions == Y) / Y.size\n\n# def gradient_descent(X, Y, LR, iterations):\n#     W1, B1, W2, B2 = init_params()\n#     one_hot_Y = one_hot(Y)\n    \n#     for i in range(iterations + 1):\n#         Z1, A1, Z2, A2 = forward_propagation(W1, B1, W2, B2, X)\n#         dW1, db1, dW2, db2 = backward_propagation(Z1, A1, Z2, A2, W1, W2, X, one_hot_Y)\n#         W1, B1, W2, B2 = update_params(W1, B1, W2, B2, dW1, db1, dW2, db2, LR)\n#         if i % 10 == 0:\n#             print(\"Iteration: \", i)\n#             predictions = get_predictions(A2)\n#             print(get_accuracy(predictions, Y))\n#     return W1, B1, W2, B2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.194567Z","iopub.execute_input":"2024-11-20T20:01:16.194901Z","iopub.status.idle":"2024-11-20T20:01:16.205809Z","shell.execute_reply.started":"2024-11-20T20:01:16.194870Z","shell.execute_reply":"2024-11-20T20:01:16.204535Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# W1, B1, W2, B2 = gradient_descent(X_train, Y_train, 0.1, 500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.207162Z","iopub.execute_input":"2024-11-20T20:01:16.207516Z","iopub.status.idle":"2024-11-20T20:01:16.227812Z","shell.execute_reply.started":"2024-11-20T20:01:16.207481Z","shell.execute_reply":"2024-11-20T20:01:16.226144Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# def make_predictions(X, W1, B1, W2, B2):\n#     _, _, _, A2 = forward_propagation(W1, B1, W2, B2, X)\n#     predictions = get_predictions(A2)\n#     return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.229053Z","iopub.execute_input":"2024-11-20T20:01:16.229419Z","iopub.status.idle":"2024-11-20T20:01:16.247663Z","shell.execute_reply.started":"2024-11-20T20:01:16.229379Z","shell.execute_reply":"2024-11-20T20:01:16.246172Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# test_predictions = make_predictions(X_test, W1, B1, W2, B2)\n# get_accuracy(test_predictions, Y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.249097Z","iopub.execute_input":"2024-11-20T20:01:16.249508Z","iopub.status.idle":"2024-11-20T20:01:16.260478Z","shell.execute_reply.started":"2024-11-20T20:01:16.249466Z","shell.execute_reply":"2024-11-20T20:01:16.259153Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class NeuralNetwork:\n    def __init__(self, X_train, Y_train, X_test, Y_test, LR, iterations):\n        self.X_train = X_train\n        self.Y_train = Y_train\n        self.Y_one_hot = self.one_hot(Y_train)\n        self.X_test = X_test\n        self.Y_test = Y_test\n        self.LR = LR\n        self.iterations = iterations\n\n        params = self.init_params([784, 100, 100, 10])\n\n        self.W1 = params['W1']\n        self.B1 = params['B1']\n        self.W2 = params['W2']\n        self.B2 = params['B2']\n        self.W3 = params['W3']\n        self.B3 = params['B3']\n\n        self.Z1 = None\n        self.Z2 = None\n        self.Z3 = None\n        self.A1 = None\n        self.A2 = None\n        self.A3 = None\n\n        self.dW1 = None\n        self.dB1 = None\n        self.dW2 = None\n        self.dB2 = None\n        self.dW3 = None\n        self.dB3 = None\n\n    def init_params(self, layer_dimensions):\n        params = {}\n    \n        for l in range(1, len(layer_dimensions)):\n            current_layer_dimension = layer_dimensions[l]\n            previous_layer_dimension = layer_dimensions[l - 1]\n            params[f\"W{l}\"] = np.random.randn(current_layer_dimension, previous_layer_dimension) * np.sqrt(2 / previous_layer_dimension)\n            params[f\"B{l}\"] = np.random.randn(current_layer_dimension, 1)\n    \n        return params\n\n    def one_hot(self, Y):\n        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n        one_hot_Y[np.arange(Y.size), Y] = 1\n        return one_hot_Y.T\n    \n    def ReLU(self, Z):\n        return np.maximum(Z, 0)\n\n    def derivative_of_ReLU(self, Z):\n        return Z > 0\n    \n    def LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, Z, alpha * Z)\n    \n    def derivative_of_LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, 1, alpha)\n    \n    def softmax(self, Z):\n        expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n        return expZ / np.sum(expZ, axis=0, keepdims=True)\n        \n    def forward_propagation(self, X):\n        self.Z1 = self.W1.dot(X) + self.B1\n        self.A1 = self.LeakyReLU(self.Z1)\n        \n        self.Z2 = self.W2.dot(self.A1) + self.B2\n        self.A2 = self.LeakyReLU(self.Z2)\n        \n        self.Z3 = self.W3.dot(self.A2) + self.B3\n        self.A3 = self.softmax(self.Z3)\n    \n    def backward_propagation(self, lambda_reg=0.01):\n        self.dZ3 = self.A3 - self.Y_one_hot\n        self.dW3 = 1 / m * self.dZ3.dot(self.A2.T) + (lambda_reg / m) * self.W3\n        self.dB3 = 1 / m * np.sum(self.dZ3)\n        \n        self.dZ2 = self.W3.T.dot(self.dZ3) * self.derivative_of_LeakyReLU(self.Z2)\n        self.dW2 = 1 / m * self.dZ2.dot(self.A1.T) + (lambda_reg / m) * self.W2\n        self.dB2 = 1 / m * np.sum(self.dZ2)\n        \n        self.dZ1 = self.W2.T.dot(self.dZ2) * self.derivative_of_LeakyReLU(self.Z1)\n        self.dW1 = 1 / m * self.dZ1.dot(self.X_train.T) + (lambda_reg / m) * self.W1\n        self.dB1 = 1 / m * np.sum(self.dZ1)\n    \n    def update_params(self):\n        self.W1 = self.W1 - self.LR * self.dW1\n        self.B1 = self.B1 - self.LR * self.dB1    \n        \n        self.W2 = self.W2 - self.LR * self.dW2  \n        self.B2 = self.B2 - self.LR * self.dB2\n        \n        self.W3 = self.W3 - self.LR * self.dW3  \n        self.B3 = self.B3 - self.LR * self.dB3\n    \n    def get_predictions(self, A):\n        return np.argmax(A, 0)\n    \n    def get_accuracy(self, predictions, Y):\n        return np.sum(predictions == Y) / Y.size\n    \n    def predict(self, X):\n        self.forward_propagation(X)\n        return self.get_predictions(self.A3)\n    \n    def gradient_descent(self):\n        train = []\n        test = []\n        \n        for i in range(self.iterations + 1):\n            self.forward_propagation(self.X_train)\n            self.backward_propagation()\n            self.update_params()\n            \n            training_predictions = self.get_predictions(self.A3)\n            training_accuracy = self.get_accuracy(training_predictions, self.Y_train)\n            test_predictions = self.predict(self.X_test)\n            test_accuracy = self.get_accuracy(test_predictions, self.Y_test)\n    \n            train.append(training_accuracy)\n            test.append(test_accuracy)\n    \n            if i % 10 == 0:\n                print(\"Iteration: \", i)\n                print(training_accuracy)\n    \n        return train, test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:18:36.286163Z","iopub.execute_input":"2024-11-20T20:18:36.286876Z","iopub.status.idle":"2024-11-20T20:18:36.308184Z","shell.execute_reply.started":"2024-11-20T20:18:36.286836Z","shell.execute_reply":"2024-11-20T20:18:36.306859Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"LR = 0.1\nITERATIONS = 3000\nlayer_dimensions = [784, 100, 100, 10]\n\nnn = NeuralNetwork(X_train, Y_train, X_test, Y_test, LR, ITERATIONS, layer_dimensions)\ntrain, test = nn.gradient_descent()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:18:39.777205Z","iopub.execute_input":"2024-11-20T20:18:39.777638Z","iopub.status.idle":"2024-11-20T20:18:49.281517Z","shell.execute_reply.started":"2024-11-20T20:18:39.777603Z","shell.execute_reply":"2024-11-20T20:18:49.280352Z"}},"outputs":[{"name":"stdout","text":"Iteration:  0\n0.09925170068027211\nIteration:  10\n0.5733333333333334\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nn \u001b[38;5;241m=\u001b[39m NeuralNetwork(X_train, Y_train, X_test, Y_test, \u001b[38;5;241m0.1\u001b[39m, ITERATIONS)\n\u001b[0;32m----> 2\u001b[0m train, test \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[16], line 115\u001b[0m, in \u001b[0;36mNeuralNetwork.gradient_descent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_propagation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train)\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m    118\u001b[0m     training_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_predictions(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA3)\n","Cell \u001b[0;32mIn[16], line 86\u001b[0m, in \u001b[0;36mNeuralNetwork.backward_propagation\u001b[0;34m(self, lambda_reg)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdB2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ2)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW2\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ2) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mderivative_of_LeakyReLU(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ1)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdZ1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m (lambda_reg \u001b[38;5;241m/\u001b[39m m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW1\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdB1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdZ1)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":18},{"cell_type":"code","source":"index = 2900\ntrain[index], test[index]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.685833Z","iopub.status.idle":"2024-11-20T20:01:16.686229Z","shell.execute_reply.started":"2024-11-20T20:01:16.686053Z","shell.execute_reply":"2024-11-20T20:01:16.686073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.graph_objs as go\nimport plotly.io as pio\n\niterations = [i for i in range(ITERATIONS + 1)]\n\ntrain_data = pd.DataFrame({\n    'x': iterations,\n    'y': train\n})\n\ntest_data = pd.DataFrame({\n    'x': iterations,\n    'y': test\n})\n\ntrace1 = go.Scatter(x = train_data.x,\n                    y = train_data.y,\n                    mode = \"lines\",\n                    name = \"training\",\n                    marker = dict(color = 'rgba(16, 112, 2, 0.8)'))\n\ntrace2 = go.Scatter(x = test_data.x,\n                    y = test_data.y,\n                    mode = \"lines+markers\",\n                    name = \"test\",\n                    marker = dict(color = 'rgba(80, 26, 80, 0.8)'))\n\ndata = [trace1, trace2]\nfig = dict(data = data)\npio.show(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T20:01:16.687402Z","iopub.status.idle":"2024-11-20T20:01:16.687757Z","shell.execute_reply.started":"2024-11-20T20:01:16.687595Z","shell.execute_reply":"2024-11-20T20:01:16.687612Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class NeuralNetwork:\n    def __init__(self, X_train, Y_train, X_test, Y_test, LR, iterations, layer_dimensions):\n        self.X_train = X_train\n        self.Y_train = Y_train\n        self.Y_one_hot = self.one_hot(Y_train)\n        self.X_test = X_test\n        self.Y_test = Y_test\n        self.LR = LR\n        self.iterations = iterations\n        self.layer_dimensions = layer_dimensions\n\n        W, B = self.init_params(layer_dimensions)\n        self.W = W\n        self.B = B\n\n        self.Z = [None for i in range(len(layer_dimensions))]\n        self.Z1 = None\n        self.Z2 = None\n        self.Z3 = None\n\n        self.A = [X_train] + [None for i in range(len(layer_dimensions) - 1)]\n        self.A1 = None\n        self.A2 = None\n        self.A3 = None\n\n        self.dW1 = None\n        self.dB1 = None\n        self.dW2 = None\n        self.dB2 = None\n        self.dW3 = None\n        self.dB3 = None\n\n    def init_params(self, layer_dimensions):\n        params = {}\n        W = []\n        B = []\n    \n        for l in range(1, len(layer_dimensions)):\n            current_layer_dimension = layer_dimensions[l]\n            previous_layer_dimension = layer_dimensions[l - 1]\n            w = np.random.randn(current_layer_dimension, previous_layer_dimension) * np.sqrt(2 / previous_layer_dimension)\n            b = np.random.randn(current_layer_dimension, 1)\n            W.append(w)\n            B.append(b)\n    \n        return B, W\n\n    def one_hot(self, Y):\n        one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n        one_hot_Y[np.arange(Y.size), Y] = 1\n        return one_hot_Y.T\n    \n    def ReLU(self, Z):\n        return np.maximum(Z, 0)\n\n    def derivative_of_ReLU(self, Z):\n        return Z > 0\n    \n    def LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, Z, alpha * Z)\n    \n    def derivative_of_LeakyReLU(self, Z, alpha=0.01):\n        return np.where(Z > 0, 1, alpha)\n    \n    def softmax(self, Z):\n        expZ = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n        return expZ / np.sum(expZ, axis=0, keepdims=True)\n        \n    def _is_last_layer(layer):\n        layer == len(self.layer_dimensions) - 1\n\n    def forward_propagation(self):\n        for layer in range(1, len(self.layer_dimensions)):\n            self.Z[layer] = self.W[layer].dot(A[layer - 1]) + self.B[layer]\n\n            if is_last_layer(layer):\n                self.A[layer] = self.softmax(self.Z[layer])\n            else:\n                self.A[layer] = self.LeakyReLU(self.Z[layer])\n    \n    def backward_propagation(self, lambda_reg=0.01):\n        self.dZ3 = self.A3 - self.Y_one_hot\n        self.dW3 = 1 / m * self.dZ3.dot(self.A2.T) + (lambda_reg / m) * self.W3\n        self.dB3 = 1 / m * np.sum(self.dZ3)\n        \n        self.dZ2 = self.W3.T.dot(self.dZ3) * self.derivative_of_LeakyReLU(self.Z2)\n        self.dW2 = 1 / m * self.dZ2.dot(self.A1.T) + (lambda_reg / m) * self.W2\n        self.dB2 = 1 / m * np.sum(self.dZ2)\n        \n        self.dZ1 = self.W2.T.dot(self.dZ2) * self.derivative_of_LeakyReLU(self.Z1)\n        self.dW1 = 1 / m * self.dZ1.dot(self.X_train.T) + (lambda_reg / m) * self.W1\n        self.dB1 = 1 / m * np.sum(self.dZ1)\n    \n    def update_params(self):\n        self.W1 = self.W1 - self.LR * self.dW1\n        self.B1 = self.B1 - self.LR * self.dB1    \n        \n        self.W2 = self.W2 - self.LR * self.dW2  \n        self.B2 = self.B2 - self.LR * self.dB2\n        \n        self.W3 = self.W3 - self.LR * self.dW3  \n        self.B3 = self.B3 - self.LR * self.dB3\n    \n    def get_predictions(self, A):\n        return np.argmax(A, 0)\n    \n    def get_accuracy(self, predictions, Y):\n        return np.sum(predictions == Y) / Y.size\n    \n    def predict(self, X):\n        self.forward_propagation(X)\n        return self.get_predictions(self.A3)\n    \n    def gradient_descent(self):\n        train = []\n        test = []\n        \n        for i in range(self.iterations + 1):\n            self.forward_propagation(self.X_train)\n            self.backward_propagation()\n            self.update_params()\n            \n            training_predictions = self.get_predictions(self.A3)\n            training_accuracy = self.get_accuracy(training_predictions, self.Y_train)\n            test_predictions = self.predict(self.X_test)\n            test_accuracy = self.get_accuracy(test_predictions, self.Y_test)\n    \n            train.append(training_accuracy)\n            test.append(test_accuracy)\n    \n            if i % 10 == 0:\n                print(\"Iteration: \", i)\n                print(training_accuracy)\n    \n        return train, test\n\nLR = 0.1\nITERATIONS = 3000\nlayer_dimensions = [784, 100, 100, 10]\n\nnn = NeuralNetwork(X_train, Y_train, X_test, Y_test, LR, ITERATIONS, layer_dimensions)\ntrain, test = nn.gradient_descent()\nnn.predict(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T11:44:51.585080Z","iopub.execute_input":"2024-11-21T11:44:51.585467Z","iopub.status.idle":"2024-11-21T11:44:51.593412Z","shell.execute_reply.started":"2024-11-21T11:44:51.585431Z","shell.execute_reply":"2024-11-21T11:44:51.592334Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[array([[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]),\n None,\n None,\n None]"},"metadata":{}}],"execution_count":9}]}